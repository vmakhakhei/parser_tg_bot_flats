"""
–ê–≥—Ä–µ–≥–∞—Ç–æ—Ä –≤—Å–µ—Ö –ø–∞—Ä—Å–µ—Ä–æ–≤ - —Å–æ–±–∏—Ä–∞–µ—Ç –æ–±—ä—è–≤–ª–µ–Ω–∏—è —Å–æ –≤—Å–µ—Ö –∏—Å—Ç–æ—á–Ω–∏–∫–æ–≤
"""
import asyncio
from typing import List, Dict, Any, Optional
from scrapers.base import Listing
from scrapers.kufar import KufarScraper
from scrapers.realt import RealtByScraper
from scrapers.domovita import DomovitaScraper
from scrapers.onliner import OnlinerRealtScraper
from scrapers.gohome import GoHomeScraper
from scrapers.hata import HataScraper
from scrapers.etagi import EtagiScraper


class ListingsAggregator:
    """–ê–≥—Ä–µ–≥–∞—Ç–æ—Ä –æ–±—ä—è–≤–ª–µ–Ω–∏–π —Å–æ –≤—Å–µ—Ö —Å–∞–π—Ç–æ–≤"""
    
    # –í—Å–µ –¥–æ—Å—Ç—É–ø–Ω—ã–µ –ø–∞—Ä—Å–µ—Ä—ã
    SCRAPERS = {
        "kufar": KufarScraper,
        "realt": RealtByScraper,
        "domovita": DomovitaScraper,
        "onliner": OnlinerRealtScraper,
        "gohome": GoHomeScraper,
        "hata": HataScraper,
        "etagi": EtagiScraper,
    }
    
    def __init__(self, enabled_sources: Optional[List[str]] = None):
        """
        –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è –∞–≥—Ä–µ–≥–∞—Ç–æ—Ä–∞
        
        Args:
            enabled_sources: –°–ø–∏—Å–æ–∫ –≤–∫–ª—é—á–µ–Ω–Ω—ã—Ö –∏—Å—Ç–æ—á–Ω–∏–∫–æ–≤. 
                            –ï—Å–ª–∏ None - –∏—Å–ø–æ–ª—å–∑—É—é—Ç—Å—è –≤—Å–µ.
        """
        if enabled_sources:
            self.enabled_sources = [s.lower() for s in enabled_sources]
        else:
            self.enabled_sources = list(self.SCRAPERS.keys())
    
    async def fetch_all_listings(
        self,
        city: str = "–±–∞—Ä–∞–Ω–æ–≤–∏—á–∏",
        min_rooms: int = 1,
        max_rooms: int = 4,
        min_price: int = 0,
        max_price: int = 100000,
    ) -> List[Listing]:
        """
        –ü–æ–ª—É—á–∞–µ—Ç –æ–±—ä—è–≤–ª–µ–Ω–∏—è —Å–æ –≤—Å–µ—Ö –≤–∫–ª—é—á–µ–Ω–Ω—ã—Ö –∏—Å—Ç–æ—á–Ω–∏–∫–æ–≤
        
        Returns:
            –û–±—ä–µ–¥–∏–Ω–µ–Ω–Ω—ã–π —Å–ø–∏—Å–æ–∫ –æ–±—ä—è–≤–ª–µ–Ω–∏–π —Å–æ –≤—Å–µ—Ö —Å–∞–π—Ç–æ–≤
        """
        all_listings = []
        tasks = []
        source_names = []
        
        # –°–æ–∑–¥–∞–µ–º –∑–∞–¥–∞—á–∏ –¥–ª—è –∫–∞–∂–¥–æ–≥–æ –ø–∞—Ä—Å–µ—Ä–∞
        for source_name in self.enabled_sources:
            if source_name in self.SCRAPERS:
                scraper_class = self.SCRAPERS[source_name]
                task = self._fetch_from_source(
                    scraper_class(),
                    city, min_rooms, max_rooms, min_price, max_price
                )
                tasks.append(task)
                source_names.append(source_name)
        
        # –í—ã–ø–æ–ª–Ω—è–µ–º –≤—Å–µ –∑–∞–ø—Ä–æ—Å—ã –ø–∞—Ä–∞–ª–ª–µ–ª—å–Ω–æ
        results = await asyncio.gather(*tasks, return_exceptions=True)
        
        # –û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã
        for source_name, result in zip(source_names, results):
            if isinstance(result, Exception):
                print(f"[{source_name}] –û—à–∏–±–∫–∞: {result}")
            elif isinstance(result, list):
                all_listings.extend(result)
                print(f"[{source_name}] –ù–∞–π–¥–µ–Ω–æ: {len(result)} –æ–±—ä—è–≤–ª–µ–Ω–∏–π")
        
        # –£–¥–∞–ª—è–µ–º –¥—É–±–ª–∏–∫–∞—Ç—ã –ø–æ ID
        unique_listings = self._remove_duplicates(all_listings)
        
        # –°–æ—Ä—Ç–∏—Ä—É–µ–º –ø–æ –¥–∞—Ç–µ (–Ω–æ–≤—ã–µ –ø–µ—Ä–≤—ã–µ) - —É –Ω–∞—Å –Ω–µ—Ç –¥–∞—Ç—ã, —Å–æ—Ä—Ç–∏—Ä—É–µ–º –ø–æ —Ü–µ–Ω–µ
        unique_listings.sort(key=lambda x: x.price if x.price > 0 else 999999999)
        
        return unique_listings
    
    async def _fetch_from_source(
        self,
        scraper,
        city: str,
        min_rooms: int,
        max_rooms: int,
        min_price: int,
        max_price: int,
    ) -> List[Listing]:
        """–ü–æ–ª—É—á–∞–µ—Ç –æ–±—ä—è–≤–ª–µ–Ω–∏—è –∏–∑ –æ–¥–Ω–æ–≥–æ –∏—Å—Ç–æ—á–Ω–∏–∫–∞"""
        try:
            async with scraper:
                listings = await scraper.fetch_listings(
                    city=city,
                    min_rooms=min_rooms,
                    max_rooms=max_rooms,
                    min_price=min_price,
                    max_price=max_price,
                )
                return listings
        except Exception as e:
            print(f"[{scraper.SOURCE_NAME}] –û—à–∏–±–∫–∞ –ø–æ–ª—É—á–µ–Ω–∏—è –¥–∞–Ω–Ω—ã—Ö: {e}")
            return []
    
    def _remove_duplicates(self, listings: List[Listing]) -> List[Listing]:
        """–£–¥–∞–ª—è–µ—Ç –¥—É–±–ª–∏–∫–∞—Ç—ã –æ–±—ä—è–≤–ª–µ–Ω–∏–π"""
        seen_ids = set()
        unique = []
        
        for listing in listings:
            if listing.id not in seen_ids:
                seen_ids.add(listing.id)
                unique.append(listing)
        
        return unique
    
    @classmethod
    def get_available_sources(cls) -> List[str]:
        """–í–æ–∑–≤—Ä–∞—â–∞–µ—Ç —Å–ø–∏—Å–æ–∫ –¥–æ—Å—Ç—É–ø–Ω—ã—Ö –∏—Å—Ç–æ—á–Ω–∏–∫–æ–≤"""
        return list(cls.SCRAPERS.keys())


async def test_aggregator():
    """–¢–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ –∞–≥—Ä–µ–≥–∞—Ç–æ—Ä–∞"""
    print("üîç –¢–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ –∞–≥—Ä–µ–≥–∞—Ç–æ—Ä–∞ –æ–±—ä—è–≤–ª–µ–Ω–∏–π...\n")
    
    aggregator = ListingsAggregator()
    
    listings = await aggregator.fetch_all_listings(
        city="–±–∞—Ä–∞–Ω–æ–≤–∏—á–∏",
        min_rooms=1,
        max_rooms=3,
        min_price=0,
        max_price=50000,
    )
    
    print(f"\n{'='*50}")
    print(f"üìä –í—Å–µ–≥–æ –Ω–∞–π–¥–µ–Ω–æ —É–Ω–∏–∫–∞–ª—å–Ω—ã—Ö –æ–±—ä—è–≤–ª–µ–Ω–∏–π: {len(listings)}")
    print(f"{'='*50}\n")
    
    # –ü–æ–∫–∞–∑—ã–≤–∞–µ–º –ø–µ—Ä–≤—ã–µ 5 –æ–±—ä—è–≤–ª–µ–Ω–∏–π
    for i, listing in enumerate(listings[:5], 1):
        print(f"--- –û–±—ä—è–≤–ª–µ–Ω–∏–µ {i} ---")
        print(f"üè∑Ô∏è  –ò—Å—Ç–æ—á–Ω–∏–∫: {listing.source}")
        print(f"üè† {listing.title}")
        print(f"üí∞ –¶–µ–Ω–∞: {listing.price_formatted}")
        print(f"üö™ –ö–æ–º–Ω–∞—Ç: {listing.rooms}")
        print(f"üìê –ü–ª–æ—â–∞–¥—å: {listing.area} –º¬≤")
        print(f"üìç –ê–¥—Ä–µ—Å: {listing.address}")
        print(f"üîó URL: {listing.url}")
        print(f"üì∏ –§–æ—Ç–æ: {len(listing.photos)} —à—Ç.")
        print()
    
    # –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ –ø–æ –∏—Å—Ç–æ—á–Ω–∏–∫–∞–º
    print("üìà –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ –ø–æ –∏—Å—Ç–æ—á–Ω–∏–∫–∞–º:")
    from collections import Counter
    sources = Counter(l.source for l in listings)
    for source, count in sources.most_common():
        print(f"  ‚Ä¢ {source}: {count}")


if __name__ == "__main__":
    asyncio.run(test_aggregator())

