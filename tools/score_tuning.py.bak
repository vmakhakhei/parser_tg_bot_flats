#!/usr/bin/env python3
"""
Score tuning tool.
Usage:
  python tools/score_tuning.py --since 2026-01-20T00:00:00 --topk 5
  python tools/score_tuning.py --city "–ë–∞—Ä–∞–Ω–æ–≤–∏—á–∏" --topk 5
"""

import argparse
import json
import asyncio
import sys
from pathlib import Path
from statistics import median
from collections import defaultdict
from datetime import datetime

# –î–æ–±–∞–≤–ª—è–µ–º –∫–æ—Ä–Ω–µ–≤—É—é –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏—é –≤ path
sys.path.insert(0, str(Path(__file__).parent.parent))

# –ò–º–ø–æ—Ä—Ç—ã –ø—Ä–æ–µ–∫—Ç–∞
try:
    from database_turso import build_dynamic_query
except ImportError:
    build_dynamic_query = None

try:
    from scrapers.aggregator import apartment_dict_to_listing, group_similar_listings
except ImportError:
    raise ImportError("–ù–µ —É–¥–∞–ª–æ—Å—å –∏–º–ø–æ—Ä—Ç–∏—Ä–æ–≤–∞—Ç—å —Ñ—É–Ω–∫—Ü–∏–∏ –∏–∑ scrapers.aggregator")

from scrapers.base import Listing


# helper scoring (same formula as utils/scoring, but weights parametric)
def safe_div(a, b):
    if b in (0, None) or a is None:
        return 0.0
    try:
        return float(a) / float(b)
    except Exception:
        return 0.0


def calc_price_per_m2(listing):
    """–í—ã—á–∏—Å–ª—è–µ—Ç —Ü–µ–Ω—É –∑–∞ –º¬≤ –¥–ª—è –æ–±—ä—è–≤–ª–µ–Ω–∏—è"""
    price = getattr(listing, "price_usd", None) or getattr(listing, "price", None)
    area = getattr(listing, "area", None) or getattr(listing, "area_m2", None) or getattr(listing, "total_area", None)
    if not price or not area:
        return None
    return safe_div(price, area)


def market_median_ppm_from_list(listings):
    """–í—ã—á–∏—Å–ª—è–µ—Ç –º–µ–¥–∏–∞–Ω–Ω—É—é —Ü–µ–Ω—É –∑–∞ –º¬≤ –ø–æ –≤—Å–µ–º –æ–±—ä—è–≤–ª–µ–Ω–∏—è–º"""
    vals = [calc_price_per_m2(l) for l in listings if calc_price_per_m2(l) is not None]
    if not vals:
        return 1.0
    return median(vals)


def compute_group_features(group):
    """–í—ã—á–∏—Å–ª—è–µ—Ç —Ö–∞—Ä–∞–∫—Ç–µ—Ä–∏—Å—Ç–∏–∫–∏ –≥—Ä—É–ø–ø—ã"""
    ppms = [calc_price_per_m2(l) for l in group if calc_price_per_m2(l) is not None]
    if not ppms:
        return {"median_ppm": None, "dispersion": None, "count": len(group)}
    m = median(ppms)
    disp = 0.0
    if len(ppms) > 0 and m and max(ppms) and min(ppms):
        disp = (max(ppms) - min(ppms)) / m
    return {"median_ppm": m, "dispersion": disp, "count": len(group)}


def score_with_weights(group, market_median_ppm, weights):
    """
    –í—ã—á–∏—Å–ª—è–µ—Ç score –≥—Ä—É–ø–ø—ã —Å –∑–∞–¥–∞–Ω–Ω—ã–º–∏ –≤–µ—Å–∞–º–∏.
    
    Args:
        group: –°–ø–∏—Å–æ–∫ –æ–±—ä—è–≤–ª–µ–Ω–∏–π –≤ –≥—Ä—É–ø–ø–µ
        market_median_ppm: –ú–µ–¥–∏–∞–Ω–Ω–∞—è —Ü–µ–Ω–∞ –∑–∞ –º¬≤ –ø–æ —Ä—ã–Ω–∫—É
        weights: –ö–æ—Ä—Ç–µ–∂ (w_price, w_delta, w_disp, w_count)
    
    Returns:
        Score –≥—Ä—É–ø–ø—ã
    """
    w_price, w_delta, w_disp, w_count = weights
    feats = compute_group_features(group)
    if feats["median_ppm"] is None:
        return 0.0
    house_median = feats["median_ppm"]
    price_score = safe_div(market_median_ppm, house_median)
    delta_vs_market = safe_div(market_median_ppm - house_median, market_median_ppm)
    dispersion = feats["dispersion"] or 0.0
    dispersion_score = max(0.0, 1.0 - dispersion)
    count_score = min(feats["count"], 6) / 6.0
    score = (
        w_price * price_score +
        w_delta * delta_vs_market +
        w_disp * dispersion_score +
        w_count * count_score
    )
    return score


def normalize(values):
    """–ù–æ—Ä–º–∞–ª–∏–∑—É–µ—Ç –∑–Ω–∞—á–µ–Ω–∏—è –≤ –¥–∏–∞–ø–∞–∑–æ–Ω [0, 1]"""
    if not values:
        return []
    mn = min(values)
    mx = max(values)
    if mx == mn:
        return [0.0 for _ in values]
    return [(v - mn) / (mx - mn) for v in values]


def evaluate(weights, groups, market_median_ppm, topk=5):
    """
    –û—Ü–µ–Ω–∏–≤–∞–µ—Ç –Ω–∞–±–æ—Ä –≤–µ—Å–æ–≤ –Ω–∞ –≥—Ä—É–ø–ø–∞—Ö.
    
    Returns:
        –°–ª–æ–≤–∞—Ä—å —Å –º–µ—Ç—Ä–∏–∫–∞–º–∏ –∏ —Ç–æ–ø-K –≥—Ä—É–ø–ø–∞–º–∏
    """
    # –í—ã—á–∏—Å–ª—è–µ–º score –¥–ª—è –∫–∞–∂–¥–æ–π –≥—Ä—É–ø–ø—ã
    scored = []
    for g in groups:
        sc = score_with_weights(g, market_median_ppm, weights)
        feats = compute_group_features(g)
        scored.append({
            "group": g,
            "score": sc,
            "median_ppm": feats["median_ppm"] or 0.0,
            "dispersion": feats["dispersion"] or 0.0,
            "count": feats["count"]
        })
    
    # –°–æ—Ä—Ç–∏—Ä—É–µ–º –ø–æ score (—É–±—ã–≤–∞–Ω–∏–µ)
    scored.sort(key=lambda x: x["score"], reverse=True)
    top = scored[:topk]
    
    # –í—ã—á–∏—Å–ª—è–µ–º –º–µ—Ç—Ä–∏–∫–∏ –¥–ª—è —Ç–æ–ø-K
    ppm_vals = [x["median_ppm"] for x in top]
    disp_vals = [x["dispersion"] for x in top]
    count_vals = [x["count"] for x in top]
    
    if not ppm_vals:
        return {
            "weights": weights,
            "market_ppm_topk": None,
            "dispersion_topk": None,
            "count_topk": None,
            "objective": None,
            "top": []
        }
    
    mean_ppm = sum(ppm_vals) / len(ppm_vals)
    mean_disp = sum(disp_vals) / len(disp_vals)
    mean_count = sum(count_vals) / len(count_vals)
    
    return {
        "weights": weights,
        "market_ppm_topk": mean_ppm,
        "dispersion_topk": mean_disp,
        "count_topk": mean_count,
        "top": top
    }


async def load_listings_from_db(city=None, since=None, limit=1000):
    """
    –ó–∞–≥—Ä—É–∂–∞–µ—Ç –æ–±—ä—è–≤–ª–µ–Ω–∏—è –∏–∑ –ë–î.
    
    Args:
        city: –ì–æ—Ä–æ–¥ –¥–ª—è —Ñ–∏–ª—å—Ç—Ä–∞—Ü–∏–∏ (–æ–ø—Ü–∏–æ–Ω–∞–ª—å–Ω–æ)
        since: –î–∞—Ç–∞ –Ω–∞—á–∞–ª–∞ (–æ–ø—Ü–∏–æ–Ω–∞–ª—å–Ω–æ)
        limit: –ú–∞–∫—Å–∏–º–∞–ª—å–Ω–æ–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –æ–±—ä—è–≤–ª–µ–Ω–∏–π
    
    Returns:
        –°–ø–∏—Å–æ–∫ —Å–ª–æ–≤–∞—Ä–µ–π —Å –¥–∞–Ω–Ω—ã–º–∏ –æ–±—ä—è–≤–ª–µ–Ω–∏–π
    """
    if not build_dynamic_query:
        raise RuntimeError("build_dynamic_query –Ω–µ –¥–æ—Å—Ç—É–ø–µ–Ω (–ø—Ä–æ–≤–µ—Ä—å—Ç–µ –∏–º–ø–æ—Ä—Ç—ã)")
    
    # –ò—Å–ø–æ–ª—å–∑—É–µ–º build_dynamic_query –¥–ª—è –ø–æ–ª—É—á–µ–Ω–∏—è –¥–∞–Ω–Ω—ã—Ö
    # –ï—Å–ª–∏ —É–∫–∞–∑–∞–Ω –≥–æ—Ä–æ–¥, —Ñ–∏–ª—å—Ç—Ä—É–µ–º –ø–æ –∞–¥—Ä–µ—Å—É
    region = None
    if city:
        # –ü—Ä–æ–±—É–µ–º –Ω–∞–π—Ç–∏ –≥–æ—Ä–æ–¥ –≤ –∞–¥—Ä–µ—Å–µ
        region = city
    
    listings = await build_dynamic_query(
        min_price=None,
        max_price=None,
        rooms=None,
        region=region,
        source=None,
        is_active=True,
        limit=limit
    )
    
    return listings


async def main(args):
    """–û—Å–Ω–æ–≤–Ω–∞—è —Ñ—É–Ω–∫—Ü–∏—è"""
    print("=" * 60)
    print("Score Tuning Tool")
    print("=" * 60)
    
    # –ó–∞–≥—Ä—É–∂–∞–µ–º –æ–±—ä—è–≤–ª–µ–Ω–∏—è –∏–∑ –ë–î
    print(f"\nüì• –ó–∞–≥—Ä—É–∑–∫–∞ –æ–±—ä—è–≤–ª–µ–Ω–∏–π –∏–∑ –ë–î...")
    if args.city:
        print(f"   –ì–æ—Ä–æ–¥: {args.city}")
        raw = await load_listings_from_db(city=args.city, limit=2000)
    elif args.since:
        print(f"   –° –¥–∞—Ç—ã: {args.since}")
        raw = await load_listings_from_db(since=args.since, limit=2000)
    else:
        print("   –í—Å–µ –∞–∫—Ç–∏–≤–Ω—ã–µ –æ–±—ä—è–≤–ª–µ–Ω–∏—è")
        raw = await load_listings_from_db(limit=2000)
    
    print(f"‚úÖ –ó–∞–≥—Ä—É–∂–µ–Ω–æ {len(raw)} –∑–∞–ø–∏—Å–µ–π –∏–∑ –ë–î")
    
    # –ö–æ–Ω–≤–µ—Ä—Ç–∏—Ä—É–µ–º –≤ Listing –æ–±—ä–µ–∫—Ç—ã
    print(f"\nüîÑ –ö–æ–Ω–≤–µ—Ä—Ç–∞—Ü–∏—è –≤ Listing –æ–±—ä–µ–∫—Ç—ã...")
    listings = []
    for r in raw:
        try:
            l = await apartment_dict_to_listing(r)
            if l:
                listings.append(l)
        except Exception as e:
            continue
    
    print(f"‚úÖ –ö–æ–Ω–≤–µ—Ä—Ç–∏—Ä–æ–≤–∞–Ω–æ {len(listings)} –æ–±—ä—è–≤–ª–µ–Ω–∏–π")
    
    if not listings:
        print("‚ùå –ù–µ—Ç –æ–±—ä—è–≤–ª–µ–Ω–∏–π –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞!")
        return
    
    # –ì—Ä—É–ø–ø–∏—Ä—É–µ–º –æ–±—ä—è–≤–ª–µ–Ω–∏—è
    print(f"\nüìä –ì—Ä—É–ø–ø–∏—Ä–æ–≤–∫–∞ –æ–±—ä—è–≤–ª–µ–Ω–∏–π...")
    groups = group_similar_listings(listings)
    print(f"‚úÖ –°–æ–∑–¥–∞–Ω–æ {len(groups)} –≥—Ä—É–ø–ø")
    
    if not groups:
        print("‚ùå –ù–µ—Ç –≥—Ä—É–ø–ø –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞!")
        return
    
    # –í—ã—á–∏—Å–ª—è–µ–º –º–µ–¥–∏–∞–Ω–Ω—É—é —Ü–µ–Ω—É –∑–∞ –º¬≤ –ø–æ —Ä—ã–Ω–∫—É
    market_ppm = market_median_ppm_from_list(listings)
    print(f"\nüí∞ –ú–µ–¥–∏–∞–Ω–Ω–∞—è —Ü–µ–Ω–∞ –∑–∞ –º¬≤ –ø–æ —Ä—ã–Ω–∫—É: {market_ppm:.2f}")
    
    # –ù–∞–±–æ—Ä –∫–∞–Ω–¥–∏–¥–∞—Ç–æ–≤ –≤–µ—Å–æ–≤
    candidate_weights = [
        (0.45, 0.25, 0.15, 0.15),  # baseline
        (0.55, 0.20, 0.15, 0.10),  # price_heavy
        (0.40, 0.20, 0.25, 0.15),  # dispersion_heavy
        (0.35, 0.20, 0.15, 0.30),  # count_favor
        (0.50, 0.30, 0.10, 0.10),  # conservative
        (0.30, 0.30, 0.20, 0.20),  # balanced
        (0.30, 0.20, 0.30, 0.20),  # low_price
    ]
    
    weight_names = [
        "baseline",
        "price_heavy",
        "dispersion_heavy",
        "count_favor",
        "conservative",
        "balanced",
        "low_price"
    ]
    
    print(f"\nüß™ –¢–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ {len(candidate_weights)} –Ω–∞–±–æ—Ä–æ–≤ –≤–µ—Å–æ–≤...")
    print(f"   Top-K: {args.topk}")
    
    # –û—Ü–µ–Ω–∏–≤–∞–µ–º –∫–∞–∂–¥—ã–π –Ω–∞–±–æ—Ä –≤–µ—Å–æ–≤
    results = []
    for i, w in enumerate(candidate_weights):
        name = weight_names[i] if i < len(weight_names) else f"weights_{i}"
        print(f"   [{i+1}/{len(candidate_weights)}] {name}: {w}")
        res = evaluate(w, groups, market_ppm, topk=args.topk)
        res["name"] = name
        results.append(res)
    
    # –í—ã—á–∏—Å–ª—è–µ–º composite objective
    print(f"\nüìà –í—ã—á–∏—Å–ª–µ–Ω–∏–µ composite objective...")
    
    ppm_vals = [r["market_ppm_topk"] or 0 for r in results]
    disp_vals = [r["dispersion_topk"] or 0 for r in results]
    count_vals = [r["count_topk"] or 0 for r in results]
    
    ppm_norm = normalize(ppm_vals)
    disp_norm = normalize(disp_vals)
    count_penalty = [abs(c - 3) / 3.0 for c in count_vals]
    
    # –í–µ—Å–∞ –¥–ª—è composite objective
    alpha = 0.5   # –≤–∞–∂–Ω–æ—Å—Ç—å ppm (—á–µ–º –Ω–∏–∂–µ - —Ç–µ–º –ª—É—á—à–µ)
    beta = 0.3    # –≤–∞–∂–Ω–æ—Å—Ç—å dispersion (—á–µ–º –Ω–∏–∂–µ - —Ç–µ–º –ª—É—á—à–µ)
    gamma = 0.2   # –≤–∞–∂–Ω–æ—Å—Ç—å count penalty (—á–µ–º –±–ª–∏–∂–µ –∫ 3 - —Ç–µ–º –ª—É—á—à–µ)
    
    final = []
    for i, r in enumerate(results):
        obj = alpha * ppm_norm[i] + beta * disp_norm[i] + gamma * count_penalty[i]
        final.append({
            "name": r["name"],
            "weights": r["weights"],
            "market_ppm_topk": r["market_ppm_topk"],
            "dispersion_topk": r["dispersion_topk"],
            "count_topk": r["count_topk"],
            "objective": obj
        })
    
    # –°–æ—Ä—Ç–∏—Ä—É–µ–º –ø–æ objective (–º–µ–Ω—å—à–µ = –ª—É—á—à–µ)
    final_sorted = sorted(final, key=lambda x: x["objective"])
    
    print("\n" + "=" * 60)
    print("üìä –†–ï–ó–£–õ–¨–¢–ê–¢–´ (–º–µ–Ω—å—à–µ objective = –ª—É—á—à–µ)")
    print("=" * 60)
    
    for i, res in enumerate(final_sorted, 1):
        print(f"\n{i}. {res['name']}")
        print(f"   –í–µ—Å–∞: {res['weights']}")
        print(f"   market_ppm_topk: {res['market_ppm_topk']:.2f}")
        print(f"   dispersion_topk: {res['dispersion_topk']:.4f}")
        print(f"   count_topk: {res['count_topk']:.2f}")
        print(f"   objective: {res['objective']:.4f}")
    
    # –°–æ—Ö—Ä–∞–Ω—è–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã –≤ —Ñ–∞–π–ª
    output_file = Path(__file__).parent / "score_tuning_results.json"
    
    # –ü–æ–¥–≥–æ—Ç–æ–≤–∫–∞ –¥–∞–Ω–Ω—ã—Ö –¥–ª—è —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è (—É–±–∏—Ä–∞–µ–º –≥—Ä—É–ø–ø—ã –∏–∑ top, –æ—Å—Ç–∞–≤–ª—è–µ–º —Ç–æ–ª—å–∫–æ –º–µ—Ç—Ä–∏–∫–∏)
    results_to_save = []
    for res in final_sorted:
        results_to_save.append({
            "name": res["name"],
            "weights": res["weights"],
            "market_ppm_topk": res["market_ppm_topk"],
            "dispersion_topk": res["dispersion_topk"],
            "count_topk": res["count_topk"],
            "objective": res["objective"]
        })
    
    output_file.write_text(
        json.dumps(results_to_save, indent=2, ensure_ascii=False),
        encoding="utf-8"
    )
    
    print(f"\nüíæ –†–µ–∑—É–ª—å—Ç–∞—Ç—ã —Å–æ—Ö—Ä–∞–Ω–µ–Ω—ã –≤: {output_file}")
    
    # –ü–æ–∫–∞–∑—ã–≤–∞–µ–º —Ç–æ–ø-3
    print("\n" + "=" * 60)
    print("üèÜ –¢–û–ü-3 –†–ï–ö–û–ú–ï–ù–î–£–ï–ú–´–• –ù–ê–ë–û–†–ê –í–ï–°–û–í")
    print("=" * 60)
    
    for i, res in enumerate(final_sorted[:3], 1):
        print(f"\n{i}. {res['name']}")
        print(f"   –í–µ—Å–∞ (price, delta, dispersion, count): {res['weights']}")
        print(f"   market_ppm_topk: {res['market_ppm_topk']:.2f}")
        print(f"   dispersion_topk: {res['dispersion_topk']:.4f}")
        print(f"   count_topk: {res['count_topk']:.2f}")
        print(f"   objective: {res['objective']:.4f}")


if __name__ == "__main__":
    parser = argparse.ArgumentParser(
        description="–ò–Ω—Å—Ç—Ä—É–º–µ–Ω—Ç –¥–ª—è –Ω–∞—Å—Ç—Ä–æ–π–∫–∏ –≤–µ—Å–æ–≤ scoring"
    )
    parser.add_argument(
        "--since",
        type=str,
        default=None,
        help="–î–∞—Ç–∞ –Ω–∞—á–∞–ª–∞ –≤ —Ñ–æ—Ä–º–∞—Ç–µ ISO (–Ω–∞–ø—Ä–∏–º–µ—Ä, 2026-01-18T00:00:00)"
    )
    parser.add_argument(
        "--city",
        type=str,
        default=None,
        help="–ì–æ—Ä–æ–¥ –¥–ª—è —Ñ–∏–ª—å—Ç—Ä–∞—Ü–∏–∏ (–Ω–∞–ø—Ä–∏–º–µ—Ä, '–ë–∞—Ä–∞–Ω–æ–≤–∏—á–∏')"
    )
    parser.add_argument(
        "--topk",
        type=int,
        default=5,
        help="–ö–æ–ª–∏—á–µ—Å—Ç–≤–æ —Ç–æ–ø –≥—Ä—É–ø–ø –¥–ª—è –æ—Ü–µ–Ω–∫–∏ (–ø–æ —É–º–æ–ª—á–∞–Ω–∏—é 5)"
    )
    
    args = parser.parse_args()
    
    # –ó–∞–ø—É—Å–∫–∞–µ–º async —Ñ—É–Ω–∫—Ü–∏—é
    asyncio.run(main(args))
