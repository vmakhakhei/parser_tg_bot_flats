"""
–°–µ—Ä–≤–∏—Å –¥–ª—è –ø–æ–∏—Å–∫–∞ –∏ —Ñ–∏–ª—å—Ç—Ä–∞—Ü–∏–∏ –æ–±—ä—è–≤–ª–µ–Ω–∏–π
"""

import logging
import json
import time
from typing import List, Dict, Any, Optional, Tuple

from scrapers.aggregator import ListingsAggregator
from scrapers.base import Listing
from database import (
    get_active_users,
    is_ad_sent_to_user,
    is_duplicate_content,
)
from database_turso import get_user_filters_turso, has_valid_user_filters
from database import is_ad_sent_to_user, mark_ad_sent_to_user
from scrapers.utils.id_utils import normalize_ad_id, normalize_telegram_id
from error_logger import log_info, log_warning, log_error
from config import DEFAULT_SOURCES, USE_TURSO_CACHE

logger = logging.getLogger(__name__)

# –°—á–µ—Ç—á–∏–∫–∏ –¥–ª—è –æ–≥—Ä–∞–Ω–∏—á–µ–Ω–∏—è –ª–æ–≥–∏—Ä–æ–≤–∞–Ω–∏—è
_filter_log_counters: Dict[int, Dict[str, int]] = {}
_MAX_FILTERED_LOGS = 20  # –ú–∞–∫—Å–∏–º—É–º –ª–æ–≥–æ–≤ –æ—Ç—Ñ–∏–ª—å—Ç—Ä–æ–≤–∞–Ω–Ω—ã—Ö –æ–±—ä—è–≤–ª–µ–Ω–∏–π
_MAX_PASSED_LOGS = 10  # –ú–∞–∫—Å–∏–º—É–º –ª–æ–≥–æ–≤ –ø—Ä–æ—à–µ–¥—à–∏—Ö –æ–±—ä—è–≤–ª–µ–Ω–∏–π


def validate_user_filters(user_filters: Dict[str, Any]) -> Tuple[bool, Optional[str]]:
    """–ü—Ä–æ–≤–µ—Ä—è–µ—Ç –≤–∞–ª–∏–¥–Ω–æ—Å—Ç—å —Ñ–∏–ª—å—Ç—Ä–æ–≤ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è.

    Returns:
        –ö–æ—Ä—Ç–µ–∂ (is_valid, error_message)
    """
    if not user_filters:
        return False, "–§–∏–ª—å—Ç—Ä—ã –Ω–µ –Ω–∞—Å—Ç—Ä–æ–µ–Ω—ã"

    if not user_filters.get("city"):
        return False, "–ì–æ—Ä–æ–¥ –Ω–µ –≤—ã–±—Ä–∞–Ω"

    return True, None


def _log_filtered_listing(
    user_prefix: str,
    listing: Listing,
    reason: str,
    user_id: Optional[int],
) -> None:
    """–õ–æ–≥–∏—Ä—É–µ—Ç –æ—Ç—Ñ–∏–ª—å—Ç—Ä–æ–≤–∞–Ω–Ω–æ–µ –æ–±—ä—è–≤–ª–µ–Ω–∏–µ."""
    if not user_id:
        return

    counter = _filter_log_counters.get(user_id, {"filtered": 0, "passed": 0})
    if counter["filtered"] < _MAX_FILTERED_LOGS:
        log_info(
            "filter",
            f"{user_prefix} ‚ùå –û—Ç—Ñ–∏–ª—å—Ç—Ä–æ–≤–∞–Ω–æ {reason}: {listing.id} "
            f"({listing.source}) - {listing.rooms}–∫, "
            f"{listing.price_formatted}, –∞–¥—Ä–µ—Å: {listing.address}",
        )
        counter["filtered"] += 1


def _check_rooms_filter(
    listing: Listing,
    filters: Dict[str, Any],
    user_prefix: str,
    user_id: Optional[int],
    log_details: bool,
) -> bool:
    """–ü—Ä–æ–≤–µ—Ä—è–µ—Ç —Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤–∏–µ –æ–±—ä—è–≤–ª–µ–Ω–∏—è —Ñ–∏–ª—å—Ç—Ä—É –ø–æ –∫–æ–º–Ω–∞—Ç–∞–º."""
    if listing.rooms <= 0:
        return True

    min_rooms = filters.get("min_rooms", 1)
    max_rooms = filters.get("max_rooms", 4)

    # –í–†–ï–ú–ï–ù–ù–û –û–°–õ–ê–ë–õ–Ø–ï–ú –§–ò–õ–¨–¢–†: –µ—Å–ª–∏ –¥–∏–∞–ø–∞–∑–æ–Ω —Å–ª–∏—à–∫–æ–º —É–∑–∫–∏–π, —Ä–∞—Å—à–∏—Ä—è–µ–º –µ–≥–æ
    if max_rooms < min_rooms:
        log_warning("filter", f"[user_{user_id}] –ù–µ–∫–æ—Ä—Ä–µ–∫—Ç–Ω—ã–π —Ñ–∏–ª—å—Ç—Ä: max_rooms={max_rooms} < min_rooms={min_rooms}, –∏—Å–ø—Ä–∞–≤–ª—è—é")
        max_rooms = min_rooms + 3

    if listing.rooms < min_rooms or listing.rooms > max_rooms:
        if log_details:
            _log_filtered_listing(
                user_prefix,
                listing,
                f"–ø–æ –∫–æ–º–Ω–∞—Ç–∞–º (—Ñ–∏–ª—å—Ç—Ä: {min_rooms}-{max_rooms}–∫)",
                user_id,
            )
        return False

    return True


def _get_price_in_usd(listing: Listing) -> int:
    """–ö–æ–Ω–≤–µ—Ä—Ç–∏—Ä—É–µ—Ç —Ü–µ–Ω—É –æ–±—ä—è–≤–ª–µ–Ω–∏—è –≤ USD."""
    if listing.price_usd:
        return listing.price_usd
    elif listing.price_byn and not listing.price_usd:
        # –ö–æ–Ω–≤–µ—Ä—Ç–∏—Ä—É–µ–º BYN –≤ USD –ø—Ä–∏–º–µ—Ä–Ω–æ (–∫—É—Ä—Å ~2.95)
        return int(listing.price_byn / 2.95)
    return listing.price


def _check_price_filter(
    listing: Listing,
    filters: Dict[str, Any],
    user_prefix: str,
    user_id: Optional[int],
    log_details: bool,
) -> bool:
    """–ü—Ä–æ–≤–µ—Ä—è–µ—Ç —Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤–∏–µ –æ–±—ä—è–≤–ª–µ–Ω–∏—è —Ñ–∏–ª—å—Ç—Ä—É –ø–æ —Ü–µ–Ω–µ."""
    price = _get_price_in_usd(listing)

    if price <= 0:
        return True

    min_price = filters.get("min_price", 0)
    max_price = filters.get("max_price", 1000000)

    # –í–†–ï–ú–ï–ù–ù–û –û–°–õ–ê–ë–õ–Ø–ï–ú –§–ò–õ–¨–¢–†: –µ—Å–ª–∏ max_price —Å–ª–∏—à–∫–æ–º –º–∞–ª–µ–Ω—å–∫–∏–π, —É–≤–µ–ª–∏—á–∏–≤–∞–µ–º –µ–≥–æ
    # –≠—Ç–æ –∑–∞—â–∏—Ç–∞ –æ—Ç —Å–ª–∏—à–∫–æ–º —Å—Ç—Ä–æ–≥–∏—Ö —Ñ–∏–ª—å—Ç—Ä–æ–≤
    if max_price < 10000:  # –ï—Å–ª–∏ –º–∞–∫—Å–∏–º—É–º –º–µ–Ω—å—à–µ 10k, —ç—Ç–æ –ø–æ–¥–æ–∑—Ä–∏—Ç–µ–ª—å–Ω–æ
        log_warning("filter", f"[user_{user_id}] –ü–æ–¥–æ–∑—Ä–∏—Ç–µ–ª—å–Ω–æ –Ω–∏–∑–∫–∏–π max_price={max_price}, –æ—Å–ª–∞–±–ª—è—é —Ñ–∏–ª—å—Ç—Ä")
        max_price = 1000000

    if price < min_price or price > max_price:
        if log_details:
            _log_filtered_listing(
                user_prefix,
                listing,
                f"–ø–æ —Ü–µ–Ω–µ: ${price:,} (—Ñ–∏–ª—å—Ç—Ä: ${min_price:,}-${max_price:,})",
                user_id,
            )
        return False

    return True


def _check_seller_type_filter(
    listing: Listing,
    filters: Dict[str, Any],
    user_prefix: str,
    user_id: Optional[int],
    log_details: bool,
) -> bool:
    """–ü—Ä–æ–≤–µ—Ä—è–µ—Ç —Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤–∏–µ –æ–±—ä—è–≤–ª–µ–Ω–∏—è —Ñ–∏–ª—å—Ç—Ä—É –ø–æ —Ç–∏–ø—É –ø—Ä–æ–¥–∞–≤—Ü–∞."""
    seller_type = filters.get("seller_type")

    if not seller_type or listing.is_company is None:
        return True

    if seller_type == "owner" and listing.is_company:
        if log_details:
            _log_filtered_listing(
                user_prefix,
                listing,
                "–ø–æ —Ç–∏–ø—É –ø—Ä–æ–¥–∞–≤—Ü–∞: –∞–≥–µ–Ω—Ç—Å—Ç–≤–æ (—Ñ–∏–ª—å—Ç—Ä: —Ç–æ–ª—å–∫–æ —Å–æ–±—Å—Ç–≤–µ–Ω–Ω–∏–∫–∏)",
                user_id,
            )
        return False

    if seller_type == "company" and not listing.is_company:
        if log_details:
            _log_filtered_listing(
                user_prefix,
                listing,
                "–ø–æ —Ç–∏–ø—É –ø—Ä–æ–¥–∞–≤—Ü–∞: —Å–æ–±—Å—Ç–≤–µ–Ω–Ω–∏–∫ (—Ñ–∏–ª—å—Ç—Ä: —Ç–æ–ª—å–∫–æ –∞–≥–µ–Ω—Ç—Å—Ç–≤–∞)",
                user_id,
            )
        return False

    return True


def _log_passed_listing(
    user_prefix: str,
    listing: Listing,
    user_id: Optional[int],
) -> None:
    """–õ–æ–≥–∏—Ä—É–µ—Ç –æ–±—ä—è–≤–ª–µ–Ω–∏–µ, –ø—Ä–æ—à–µ–¥—à–µ–µ –≤—Å–µ —Ñ–∏–ª—å—Ç—Ä—ã."""
    if not user_id:
        return

    # –ò–∑–≤–ª–µ–∫–∞–µ–º vendor (agency –∏–ª–∏ seller) –∏–∑ raw_json
    vendor = None
    try:
        if hasattr(listing, 'raw_json') and listing.raw_json:
            if isinstance(listing.raw_json, dict):
                vendor = listing.raw_json.get('agency') or listing.raw_json.get('seller')
            elif isinstance(listing.raw_json, str):
                import json
                try:
                    raw_data = json.loads(listing.raw_json)
                    vendor = raw_data.get('agency') or raw_data.get('seller')
                except:
                    pass
    except Exception:
        vendor = None

    counter = _filter_log_counters.get(user_id, {"filtered": 0, "passed": 0})
    if counter["passed"] < _MAX_PASSED_LOGS:
        vendor_text = f", vendor={vendor}" if vendor else ", vendor=UNKNOWN"
        price_text = f"${listing.price_usd:,}" if listing.price_usd else listing.price_formatted
        log_info(
            "filter",
            f"{user_prefix} ‚úÖ –ü—Ä–æ—à–ª–æ —Ñ–∏–ª—å—Ç—Ä—ã: {listing.id} "
            f"({listing.source}) - {listing.title}, "
            f"{price_text}, –∞–¥—Ä–µ—Å: {listing.address}{vendor_text}",
        )
        counter["passed"] += 1


def matches_user_filters(
    listing: Listing,
    filters: Dict[str, Any],
    user_id: Optional[int] = None,
    log_details: bool = True,
) -> bool:
    """–ü—Ä–æ–≤–µ—Ä—è–µ—Ç —Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤–∏–µ –æ–±—ä—è–≤–ª–µ–Ω–∏—è —Ñ–∏–ª—å—Ç—Ä–∞–º –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è.

    Args:
        listing: –û–±—ä—è–≤–ª–µ–Ω–∏–µ –¥–ª—è –ø—Ä–æ–≤–µ—Ä–∫–∏
        filters: –§–∏–ª—å—Ç—Ä—ã –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è
        user_id: ID –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è (–¥–ª—è –ª–æ–≥–∏—Ä–æ–≤–∞–Ω–∏—è)
        log_details: –õ–æ–≥–∏—Ä–æ–≤–∞—Ç—å –¥–µ—Ç–∞–ª–∏ —Ñ–∏–ª—å—Ç—Ä–∞—Ü–∏–∏

    Returns:
        True –µ—Å–ª–∏ –æ–±—ä—è–≤–ª–µ–Ω–∏–µ —Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤—É–µ—Ç —Ñ–∏–ª—å—Ç—Ä–∞–º
    """
    user_prefix = f"[user_{user_id}]" if user_id else "[filter]"

    # –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä—É–µ–º —Å—á–µ—Ç—á–∏–∫ –¥–ª—è –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è
    if user_id and user_id not in _filter_log_counters:
        _filter_log_counters[user_id] = {"filtered": 0, "passed": 0}

    # –ü—Ä–æ–≤–µ—Ä—è–µ–º —Ñ–∏–ª—å—Ç—Ä—ã –ø–æ –ø–æ—Ä—è–¥–∫—É
    if not _check_rooms_filter(listing, filters, user_prefix, user_id, log_details):
        return False

    if not _check_price_filter(listing, filters, user_prefix, user_id, log_details):
        return False

    if not _check_seller_type_filter(listing, filters, user_prefix, user_id, log_details):
        return False

    # –ï—Å–ª–∏ –ø—Ä–æ—à–ª–∏ –≤—Å–µ —Ñ–∏–ª—å—Ç—Ä—ã - –ª–æ–≥–∏—Ä—É–µ–º —É—Å–ø–µ—à–Ω–æ–µ –ø—Ä–æ—Ö–æ–∂–¥–µ–Ω–∏–µ
    if log_details:
        _log_passed_listing(user_prefix, listing, user_id)

    return True


async def _get_cached_listings(
    user_id: int,
    user_city: str,
    user_filters: Dict[str, Any],
) -> List[Listing]:
    """–ü–æ–ª—É—á–∞–µ—Ç –æ–±—ä—è–≤–ª–µ–Ω–∏—è –∏–∑ –∫—ç—à–∞ Turso."""
    cached_listings: List[Listing] = []

    if not USE_TURSO_CACHE:
        return cached_listings

    try:
        from database import (
            get_cached_listings_by_filters_turso,
            cached_listing_to_listing_turso,
        )

        cached_data = await get_cached_listings_by_filters_turso(
            city=user_city,
            min_rooms=user_filters.get("min_rooms", 1),
            max_rooms=user_filters.get("max_rooms", 5),
            min_price=user_filters.get("min_price", 0),
            max_price=user_filters.get("max_price", 1000000),
            limit=200,
        )

        for cached_dict in cached_data:
            try:
                listing = cached_listing_to_listing_turso(cached_dict)
                if listing:
                    cached_listings.append(listing)
            except Exception as e:
                log_warning("search", f"–û—à–∏–±–∫–∞ –∫–æ–Ω–≤–µ—Ä—Ç–∞—Ü–∏–∏ –æ–±—ä—è–≤–ª–µ–Ω–∏—è –∏–∑ –∫—ç—à–∞: {e}")
                continue

        log_info(
            "search",
            f"üì¶ –ù–∞–π–¥–µ–Ω–æ {len(cached_listings)} –æ–±—ä—è–≤–ª–µ–Ω–∏–π –≤ –∫—ç—à–µ " f"–¥–ª—è –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è {user_id}",
        )
    except Exception as e:
        log_warning("search", f"–û—à–∏–±–∫–∞ –ø–æ–ª—É—á–µ–Ω–∏—è –¥–∞–Ω–Ω—ã—Ö –∏–∑ –∫—ç—à–∞, –∏—Å–ø–æ–ª—å–∑—É–µ–º –ø–∞—Ä—Å–∏–Ω–≥: {e}")

    return cached_listings


async def _parse_and_cache_listings(
    user_city: str,
    user_filters: Dict[str, Any],
    cached_listings: List[Listing],
) -> List[Listing]:
    """–ü–∞—Ä—Å–∏—Ç —Å–∞–π—Ç—ã –∏ —Å–æ—Ö—Ä–∞–Ω—è–µ—Ç –æ–±—ä—è–≤–ª–µ–Ω–∏—è –≤ –∫—ç—à."""
    log_info(
        "search",
        f"üîç –í –∫—ç—à–µ –º–∞–ª–æ –æ–±—ä—è–≤–ª–µ–Ω–∏–π ({len(cached_listings)}), –ø–∞—Ä—Å–∏–º —Å–∞–π—Ç—ã...",
    )

    # #region agent log
    try:
        with open('/Users/vmakhakei/TG BOT/.cursor/debug.log', 'a') as f:
            f.write(json.dumps({"sessionId":"debug-session","runId":"run1","hypothesisId":"C","location":"search_service.py:292","message":"Starting aggregator fetch","data":{"city":user_city,"min_rooms":user_filters.get("min_rooms",1),"max_rooms":user_filters.get("max_rooms",5),"min_price":user_filters.get("min_price",0),"max_price":user_filters.get("max_price",1000000)},"timestamp":int(time.time()*1000)})+'\n')
    except: pass
    # #endregion
    aggregator = ListingsAggregator(enabled_sources=DEFAULT_SOURCES)
    parsed_listings = await aggregator.fetch_all_listings(
        city=user_city,
        min_rooms=user_filters.get("min_rooms", 1),
        max_rooms=user_filters.get("max_rooms", 5),
        min_price=user_filters.get("min_price", 0),
        max_price=user_filters.get("max_price", 1000000),
    )
    # #region agent log
    try:
        with open('/Users/vmakhakei/TG BOT/.cursor/debug.log', 'a') as f:
            f.write(json.dumps({"sessionId":"debug-session","runId":"run1","hypothesisId":"C","location":"search_service.py:300","message":"Aggregator fetch completed","data":{"count":len(parsed_listings) if parsed_listings else 0,"is_none":parsed_listings is None,"type":str(type(parsed_listings))},"timestamp":int(time.time()*1000)})+'\n')
    except: pass
    # #endregion

    # –î–ò–ê–ì–ù–û–°–¢–ò–ö–ê: –ø—Ä–æ–≤–µ—Ä—è–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç –ø–∞—Ä—Å–∏–Ω–≥–∞
    if parsed_listings is None:
        log_error("search", "‚ùå Aggregator –≤–µ—Ä–Ω—É–ª None –≤–º–µ—Å—Ç–æ —Å–ø–∏—Å–∫–∞ –æ–±—ä—è–≤–ª–µ–Ω–∏–π!")
        return cached_listings

    if not isinstance(parsed_listings, list):
        log_error("search", f"‚ùå Aggregator –≤–µ—Ä–Ω—É–ª –Ω–µ —Å–ø–∏—Å–æ–∫: {type(parsed_listings)}")
        return cached_listings

    log_info("search", f"üì• –ü–∞—Ä—Å–µ—Ä—ã –≤–µ—Ä–Ω—É–ª–∏ {len(parsed_listings)} –æ–±—ä—è–≤–ª–µ–Ω–∏–π")

    # –°–æ—Ö—Ä–∞–Ω—è–µ–º –≤—Å–µ –Ω–∞–π–¥–µ–Ω–Ω—ã–µ –æ–±—ä—è–≤–ª–µ–Ω–∏—è –≤ –∫—ç—à
    if USE_TURSO_CACHE and parsed_listings:
        try:
            from database import cache_listings_batch_turso

            saved_count = await cache_listings_batch_turso(parsed_listings)
            log_info("search", f"üíæ –°–æ—Ö—Ä–∞–Ω–µ–Ω–æ {saved_count} –æ–±—ä—è–≤–ª–µ–Ω–∏–π –≤ –∫—ç—à")
        except Exception as e:
            log_warning("search", f"–û—à–∏–±–∫–∞ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è –≤ –∫—ç—à: {e}")

    # –û–±—ä–µ–¥–∏–Ω—è–µ–º –∫—ç—à –∏ –Ω–æ–≤—ã–µ –æ–±—ä—è–≤–ª–µ–Ω–∏—è (—É–±–∏—Ä–∞–µ–º –¥—É–±–ª–∏–∫–∞—Ç—ã –ø–æ ID)
    existing_ids = {listing.id for listing in cached_listings}
    new_listings = [listing for listing in parsed_listings if listing.id not in existing_ids]

    log_info("search", f"üìä –û–±—ä–µ–¥–∏–Ω–µ–Ω–∏–µ: –∫—ç—à={len(cached_listings)}, –Ω–æ–≤—ã—Ö={len(new_listings)}, –∏—Ç–æ–≥–æ={len(cached_listings) + len(new_listings)}")

    return cached_listings + new_listings


async def fetch_listings_for_user(user_id: int, user_filters: Dict[str, Any]) -> List[Listing]:
    """–ü–æ–ª—É—á–∞–µ—Ç –æ–±—ä—è–≤–ª–µ–Ω–∏—è –¥–ª—è –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è —Å —É—á–µ—Ç–æ–º –∫—ç—à–∏—Ä–æ–≤–∞–Ω–∏—è.

    Args:
        user_id: ID –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è
        user_filters: –§–∏–ª—å—Ç—Ä—ã –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è

    Returns:
        –°–ø–∏—Å–æ–∫ –æ–±—ä—è–≤–ª–µ–Ω–∏–π
    """
    user_city = user_filters.get("city")

    # –°–±—Ä–∞—Å—ã–≤–∞–µ–º —Å—á–µ—Ç—á–∏–∫ –ª–æ–≥–∏—Ä–æ–≤–∞–Ω–∏—è –¥–ª—è —ç—Ç–æ–≥–æ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è
    _filter_log_counters[user_id] = {"filtered": 0, "passed": 0}

    log_info(
        "filter",
        f"[user_{user_id}] üìã –ü—Ä–∏–º–µ–Ω—è—é —Ñ–∏–ª—å—Ç—Ä—ã: "
        f"–≥–æ—Ä–æ–¥={user_filters.get('city')}, "
        f"–∫–æ–º–Ω–∞—Ç—ã={user_filters.get('min_rooms')}-{user_filters.get('max_rooms')}, "
        f"—Ü–µ–Ω–∞=${user_filters.get('min_price'):,}-${user_filters.get('max_price'):,}, "
        f"–ø—Ä–æ–¥–∞–≤–µ—Ü={user_filters.get('seller_type') or '–í—Å–µ'}, "
        f"—Ä–µ–∂–∏–º={'–ò–ò' if user_filters.get('ai_mode') else '–û–±—ã—á–Ω—ã–π'}",
    )

    # –ü–æ–ª—É—á–∞–µ–º –æ–±—ä—è–≤–ª–µ–Ω–∏—è –∏–∑ –∫—ç—à–∞
    cached_listings = await _get_cached_listings(user_id, user_city, user_filters)

    # –ü–∞—Ä—Å–∏–º —Å–∞–π—Ç—ã —Ç–æ–ª—å–∫–æ –µ—Å–ª–∏ –∫—ç—à–∞ –Ω–µ—Ç –∏–ª–∏ –º–∞–ª–æ –æ–±—ä—è–≤–ª–µ–Ω–∏–π
    if len(cached_listings) < 10:
        all_listings = await _parse_and_cache_listings(user_city, user_filters, cached_listings)
    else:
        log_info(
            "search",
            f"‚úÖ –ò—Å–ø–æ–ª—å–∑—É–µ–º –∫—ç—à ({len(cached_listings)} –æ–±—ä—è–≤–ª–µ–Ω–∏–π), " "–ø–∞—Ä—Å–∏–Ω–≥ –Ω–µ —Ç—Ä–µ–±—É–µ—Ç—Å—è",
        )
        all_listings = cached_listings

    log_info(
        "search",
        f"–î–ª—è –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è {user_id} (–≥–æ—Ä–æ–¥: {user_city}) "
        f"–Ω–∞–π–¥–µ–Ω–æ –æ–±—ä—è–≤–ª–µ–Ω–∏–π: {len(all_listings)}",
    )

    return all_listings


def reset_filter_counters() -> None:
    """–°–±—Ä–∞—Å—ã–≤–∞–µ—Ç —Å—á–µ—Ç—á–∏–∫–∏ –ª–æ–≥–∏—Ä–æ–≤–∞–Ω–∏—è —Ñ–∏–ª—å—Ç—Ä–∞—Ü–∏–∏."""
    global _filter_log_counters  # noqa: F824
    _filter_log_counters.clear()


async def _process_listing_for_user(
    bot: Any,
    user_id: int,
    listing: Listing,
    user_filters: Dict[str, Any],
) -> bool:
    """–û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ—Ç –æ–¥–Ω–æ –æ–±—ä—è–≤–ª–µ–Ω–∏–µ –¥–ª—è –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è –≤ –æ–±—ã—á–Ω–æ–º —Ä–µ–∂–∏–º–µ.

    Returns:
        True –µ—Å–ª–∏ –æ–±—ä—è–≤–ª–µ–Ω–∏–µ –±—ã–ª–æ –æ—Ç–ø—Ä–∞–≤–ª–µ–Ω–æ
    """
    from bot.services.notification_service import send_listing_to_user

    # –ü—Ä–æ–≤–µ—Ä—è–µ–º —Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤–∏–µ —Ñ–∏–ª—å—Ç—Ä–∞–º –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è
    if not matches_user_filters(listing, user_filters, user_id=user_id, log_details=True):
        return False

    # –ü—Ä–æ–≤–µ—Ä—è–µ–º, –Ω–µ –æ—Ç–ø—Ä–∞–≤–ª—è–ª–∏ –ª–∏ —É–∂–µ —ç—Ç–æ–º—É –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—é
    # –í DEBUG —Ä–µ–∂–∏–º–µ –∏–≥–Ω–æ—Ä–∏—Ä—É–µ–º –ø—Ä–æ–≤–µ—Ä–∫—É sent_ads
    from bot.handlers.debug import get_debug_ignore_sent_ads
    debug_ignore_sent_ads = get_debug_ignore_sent_ads()
    
    # –õ–æ–≥–∏—Ä–æ–≤–∞–Ω–∏–µ –ø—Ä–æ–≤–µ—Ä–∫–∏ sent_ads
    ad_key = normalize_ad_id(listing.id)
    tg = normalize_telegram_id(user_id)
    already = False
    try:
        if not debug_ignore_sent_ads:
            already = await is_ad_sent_to_user(telegram_id=tg, ad_external_id=ad_key)
        else:
            logger.info(f"[sent_check][DEBUG] ignore_sent_ads=True ‚Äî –ø—Ä–æ–ø—É—Å–∫–∞—é –ø—Ä–æ–≤–µ—Ä–∫—É sent_ads –¥–ª—è user={tg} ad={ad_key}")
    except Exception as e:
        logger.exception(f"[sent_check][ERROR] user={tg} ad={ad_key} check failed: {e}")
    logger.info(f"[sent_check] user={tg} ad={ad_key} already_sent={already}")
    
    if already:
        logger.info(f"[search][skip] user={tg} skip ad={ad_key} reason=already_sent")
        return False

    # –ü—Ä–æ–≤–µ—Ä—è–µ–º –≥–ª–æ–±–∞–ª—å–Ω—É—é –¥–µ–¥—É–ø–ª–∏–∫–∞—Ü–∏—é –ø–æ –∫–æ–Ω—Ç–µ–Ω—Ç—É
    dup_check = await is_duplicate_content(
        rooms=listing.rooms,
        area=listing.area,
        address=listing.address,
        price=listing.price,
    )

    if dup_check["is_duplicate"]:
        log_info(
            "dedup",
            f"–î—É–±–ª–∏–∫–∞—Ç –¥–ª—è –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è {user_id}: " f"{listing.source} ID={listing.id}",
        )
        return False

    # –û—Ç–ø—Ä–∞–≤–ª—è–µ–º –æ–±—ä—è–≤–ª–µ–Ω–∏–µ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—é –ë–ï–ó –ò–ò-–æ—Ü–µ–Ω–∫–∏ (–æ–±—ã—á–Ω—ã–π —Ä–µ–∂–∏–º)
    return await send_listing_to_user(bot, user_id, listing, use_ai_valuation=False)


async def _process_user_listings_normal_mode(
    bot: Any,
    user_id: int,
    all_listings: List[Listing],
    user_filters: Dict[str, Any],
    *,
    ignore_sent_ads: bool = False,
    force_send: bool = False,
    bypass_summary: bool = False,
    **kwargs
) -> int:
    """–û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ—Ç –æ–±—ä—è–≤–ª–µ–Ω–∏—è –¥–ª—è –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è –≤ –æ–±—ã—á–Ω–æ–º —Ä–µ–∂–∏–º–µ.
    
    –í–ê–ñ–ù–û: –í—Å–µ –æ–±—ä—è–≤–ª–µ–Ω–∏—è –∏–∑ all_listings –£–ñ–ï —Å–æ—Ö—Ä–∞–Ω–µ–Ω—ã –≤ —Ç–∞–±–ª–∏—Ü—É apartments
    —á–µ—Ä–µ–∑ aggregator.fetch_all_listings(). –î–∞–Ω–Ω—ã–µ –Ω–µ —Ç–æ–ª—å–∫–æ –≤ –ø–∞–º—è—Ç–∏, –Ω–æ –∏ –≤ –ë–î.

    Returns:
        –ö–æ–ª–∏—á–µ—Å—Ç–≤–æ –æ—Ç–ø—Ä–∞–≤–ª–µ–Ω–Ω—ã—Ö –æ–±—ä—è–≤–ª–µ–Ω–∏–π
    """
    import asyncio

    # –î–ò–ê–ì–ù–û–°–¢–ò–ö–ê: –ª–æ–≥–∏—Ä—É–µ–º —Å–∫–æ–ª—å–∫–æ –æ–±—ä—è–≤–ª–µ–Ω–∏–π –ø–æ–ª—É—á–µ–Ω–æ
    # –í–ê–ñ–ù–û: –≠—Ç–∏ –æ–±—ä—è–≤–ª–µ–Ω–∏—è —É–∂–µ —Å–æ—Ö—Ä–∞–Ω–µ–Ω—ã –≤ apartments —á–µ—Ä–µ–∑ aggregator
    log_info("search", f"[user_{user_id}] üì• –ü–æ–ª—É—á–µ–Ω–æ –æ–±—ä—è–≤–ª–µ–Ω–∏–π –¥–ª—è –æ–±—Ä–∞–±–æ—Ç–∫–∏: {len(all_listings)} (—É–∂–µ —Å–æ—Ö—Ä–∞–Ω–µ–Ω—ã –≤ apartments)")

    if not all_listings:
        log_warning("search", f"[user_{user_id}] ‚ö†Ô∏è –ù–µ—Ç –æ–±—ä—è–≤–ª–µ–Ω–∏–π –¥–ª—è –æ–±—Ä–∞–±–æ—Ç–∫–∏!")
        return 0

    user_new_count = 0
    filtered_count = 0
    already_sent_count = 0
    duplicate_count = 0
    failed_send_count = 0
    
    import json
    import time

    # #region agent log
    try:
        with open('/Users/vmakhakei/TG BOT/.cursor/debug.log', 'a') as f:
            f.write(json.dumps({"sessionId":"debug-session","runId":"run1","hypothesisId":"H1","location":"search_service.py:461","message":"Starting processing listings","data":{"user_id":user_id,"total_listings":len(all_listings),"listing_ids":[l.id for l in all_listings[:10]]},"timestamp":int(time.time()*1000)})+'\n')
    except: pass
    # #endregion

    for idx, listing in enumerate(all_listings):
        # #region agent log
        try:
            with open('/Users/vmakhakei/TG BOT/.cursor/debug.log', 'a') as f:
                f.write(json.dumps({"sessionId":"debug-session","runId":"run1","hypothesisId":"H1","location":"search_service.py:469","message":"Processing listing","data":{"user_id":user_id,"listing_id":listing.id,"index":idx,"total":len(all_listings),"price":listing.price,"rooms":listing.rooms},"timestamp":int(time.time()*1000)})+'\n')
        except: pass
        # #endregion
        
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º —Ñ–∏–ª—å—Ç—Ä—ã
        # #region agent log
        try:
            with open('/Users/vmakhakei/TG BOT/.cursor/debug.log', 'a') as f:
                f.write(json.dumps({"sessionId":"debug-session","runId":"run1","hypothesisId":"H2","location":"search_service.py:475","message":"Checking listing filters","data":{"user_id":user_id,"listing_price":listing.price,"listing_rooms":listing.rooms,"min_price":user_filters.get("min_price"),"max_price":user_filters.get("max_price"),"min_rooms":user_filters.get("min_rooms"),"max_rooms":user_filters.get("max_rooms")},"timestamp":int(time.time()*1000)})+'\n')
        except: pass
        # #endregion
        
        if not matches_user_filters(listing, user_filters, user_id=user_id, log_details=False):
            filtered_count += 1
            # #region agent log
            try:
                with open('/Users/vmakhakei/TG BOT/.cursor/debug.log', 'a') as f:
                    f.write(json.dumps({"sessionId":"debug-session","runId":"run1","hypothesisId":"H2","location":"search_service.py:482","message":"Listing filtered out by filters","data":{"user_id":user_id,"listing_id":listing.id,"filtered_count":filtered_count},"timestamp":int(time.time()*1000)})+'\n')
            except: pass
            # #endregion
            continue

        # –ü—Ä–æ–≤–µ—Ä—è–µ–º, –Ω–µ –æ—Ç–ø—Ä–∞–≤–ª—è–ª–∏ –ª–∏ —É–∂–µ
        # #region agent log
        try:
            with open('/Users/vmakhakei/TG BOT/.cursor/debug.log', 'a') as f:
                f.write(json.dumps({"sessionId":"debug-session","runId":"run1","hypothesisId":"H3","location":"search_service.py:490","message":"Checking if already sent","data":{"user_id":user_id,"listing_id":listing.id},"timestamp":int(time.time()*1000)})+'\n')
        except: pass
        # #endregion
        
        # –í DEBUG —Ä–µ–∂–∏–º–µ –∏–≥–Ω–æ—Ä–∏—Ä—É–µ–º –ø—Ä–æ–≤–µ—Ä–∫—É sent_ads
        from bot.handlers.debug import get_debug_ignore_sent_ads
        debug_ignore_sent_ads = get_debug_ignore_sent_ads()
        
        # –õ–æ–≥–∏—Ä–æ–≤–∞–Ω–∏–µ –ø—Ä–æ–≤–µ—Ä–∫–∏ sent_ads
        ad_key = normalize_ad_id(listing.id)
        tg = normalize_telegram_id(user_id)
        already = False
        try:
            if not ignore_sent_ads and not debug_ignore_sent_ads:
                already = await is_ad_sent_to_user(telegram_id=tg, ad_external_id=ad_key)
            else:
                logger.info(f"[sent_check][DEBUG] ignore_sent_ads={ignore_sent_ads} debug_ignore={debug_ignore_sent_ads} ‚Äî –ø—Ä–æ–ø—É—Å–∫–∞—é –ø—Ä–æ–≤–µ—Ä–∫—É sent_ads –¥–ª—è user={tg} ad={ad_key}")
        except Exception as e:
            logger.exception(f"[sent_check][ERROR] user={tg} ad={ad_key} check failed: {e}")
        logger.info(f"[sent_check] user={tg} ad={ad_key} already_sent={already}")
        
        if already:
            already_sent_count += 1
            logger.info(f"[search][skip] user={tg} skip ad={ad_key} reason=already_sent")
            # #region agent log
            try:
                with open('/Users/vmakhakei/TG BOT/.cursor/debug.log', 'a') as f:
                    f.write(json.dumps({"sessionId":"debug-session","runId":"run1","hypothesisId":"H3","location":"search_service.py:494","message":"Listing already sent","data":{"user_id":user_id,"listing_id":listing.id,"already_sent_count":already_sent_count},"timestamp":int(time.time()*1000)})+'\n')
            except: pass
            # #endregion
            continue

        # –ü—Ä–æ–≤–µ—Ä—è–µ–º –¥—É–±–ª–∏–∫–∞—Ç—ã
        # #region agent log
        try:
            with open('/Users/vmakhakei/TG BOT/.cursor/debug.log', 'a') as f:
                f.write(json.dumps({"sessionId":"debug-session","runId":"run1","hypothesisId":"H4","location":"search_service.py:500","message":"Checking duplicates","data":{"user_id":user_id,"listing_id":listing.id,"rooms":listing.rooms,"area":listing.area,"address":listing.address,"price":listing.price},"timestamp":int(time.time()*1000)})+'\n')
        except: pass
        # #endregion
        
        dup_check = await is_duplicate_content(
            rooms=listing.rooms,
            area=listing.area,
            address=listing.address,
            price=listing.price,
        )

        if dup_check["is_duplicate"]:
            duplicate_count += 1
            # #region agent log
            try:
                with open('/Users/vmakhakei/TG BOT/.cursor/debug.log', 'a') as f:
                    f.write(json.dumps({"sessionId":"debug-session","runId":"run1","hypothesisId":"H4","location":"search_service.py:512","message":"Listing is duplicate","data":{"user_id":user_id,"listing_id":listing.id,"duplicate_count":duplicate_count},"timestamp":int(time.time()*1000)})+'\n')
            except: pass
            # #endregion
            continue

        # –û—Ç–ø—Ä–∞–≤–ª—è–µ–º –æ–±—ä—è–≤–ª–µ–Ω–∏–µ
        # –í–ê–ñ–ù–û: —Ñ–∏–ª—å—Ç—Ä—ã, –ø—Ä–æ–≤–µ—Ä–∫–∞ "—É–∂–µ –æ—Ç–ø—Ä–∞–≤–ª–µ–Ω–æ" –∏ –¥—É–±–ª–∏–∫–∞—Ç—ã —É–∂–µ –ø—Ä–æ–≤–µ—Ä–µ–Ω—ã –≤—ã—à–µ
        try:
            from bot.services.notification_service import send_listing_to_user
            
            # –û—Ç–ø—Ä–∞–≤–ª—è–µ–º –æ–±—ä—è–≤–ª–µ–Ω–∏–µ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—é –ë–ï–ó –ò–ò-–æ—Ü–µ–Ω–∫–∏ (–æ–±—ã—á–Ω—ã–π —Ä–µ–∂–∏–º)
            # #region agent log
            try:
                with open('/Users/vmakhakei/TG BOT/.cursor/debug.log', 'a') as f:
                    f.write(json.dumps({"sessionId":"debug-session","runId":"run1","hypothesisId":"H5","location":"search_service.py:540","message":"Attempting to send listing","data":{"user_id":user_id,"listing_id":listing.id,"current_sent":user_new_count},"timestamp":int(time.time()*1000)})+'\n')
            except: pass
            # #endregion
            
            send_result = await send_listing_to_user(bot, user_id, listing, use_ai_valuation=False)
            
            # #region agent log
            try:
                with open('/Users/vmakhakei/TG BOT/.cursor/debug.log', 'a') as f:
                    f.write(json.dumps({"sessionId":"debug-session","runId":"run1","hypothesisId":"H5","location":"search_service.py:545","message":"Send listing result","data":{"user_id":user_id,"listing_id":listing.id,"send_result":send_result},"timestamp":int(time.time()*1000)})+'\n')
            except: pass
            # #endregion
            
            if send_result:
                user_new_count += 1
                log_info("search", f"[user_{user_id}] ‚úÖ –û—Ç–ø—Ä–∞–≤–ª–µ–Ω–æ –æ–±—ä—è–≤–ª–µ–Ω–∏–µ {listing.id} ({user_new_count}/{len(all_listings)})")
                # –ó–∞–¥–µ—Ä–∂–∫–∞ –º–µ–∂–¥—É —Å–æ–æ–±—â–µ–Ω–∏—è–º–∏ —á—Ç–æ–±—ã –Ω–µ –ø–æ–ª—É—á–∏—Ç—å –±–∞–Ω
                await asyncio.sleep(1)
            else:
                failed_send_count += 1
                log_warning("search", f"[user_{user_id}] ‚ö†Ô∏è –ù–µ —É–¥–∞–ª–æ—Å—å –æ—Ç–ø—Ä–∞–≤–∏—Ç—å –æ–±—ä—è–≤–ª–µ–Ω–∏–µ {listing.id}")
                # #region agent log
                try:
                    with open('/Users/vmakhakei/TG BOT/.cursor/debug.log', 'a') as f:
                        f.write(json.dumps({"sessionId":"debug-session","runId":"run1","hypothesisId":"H5","location":"search_service.py:556","message":"Failed to send listing","data":{"user_id":user_id,"listing_id":listing.id,"failed_send_count":failed_send_count},"timestamp":int(time.time()*1000)})+'\n')
                except: pass
                # #endregion
        except Exception as e:
            failed_send_count += 1
            log_error("search", f"[user_{user_id}] ‚ùå –û—à–∏–±–∫–∞ –æ—Ç–ø—Ä–∞–≤–∫–∏ –æ–±—ä—è–≤–ª–µ–Ω–∏—è {listing.id}", e)
            # #region agent log
            try:
                with open('/Users/vmakhakei/TG BOT/.cursor/debug.log', 'a') as f:
                    f.write(json.dumps({"sessionId":"debug-session","runId":"run1","hypothesisId":"H6","location":"search_service.py:563","message":"Exception sending listing","data":{"user_id":user_id,"listing_id":listing.id,"error":str(e),"failed_send_count":failed_send_count},"timestamp":int(time.time()*1000)})+'\n')
            except: pass
            # #endregion
            continue

    # –î–ò–ê–ì–ù–û–°–¢–ò–ö–ê: –ª–æ–≥–∏—Ä—É–µ–º —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫—É —Ñ–∏–ª—å—Ç—Ä–∞—Ü–∏–∏
    # #region agent log
    try:
        with open('/Users/vmakhakei/TG BOT/.cursor/debug.log', 'a') as f:
            f.write(json.dumps({"sessionId":"debug-session","runId":"run1","hypothesisId":"H7","location":"search_service.py:575","message":"Final statistics","data":{"user_id":user_id,"total":len(all_listings),"filtered":filtered_count,"already_sent":already_sent_count,"duplicates":duplicate_count,"sent":user_new_count,"failed_send":failed_send_count},"timestamp":int(time.time()*1000)})+'\n')
    except: pass
    # #endregion
    
    log_info(
        "search",
        f"[user_{user_id}] üìä –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ –æ–±—Ä–∞–±–æ—Ç–∫–∏: "
        f"–≤—Å–µ–≥–æ={len(all_listings)}, "
        f"–æ—Ç—Ñ–∏–ª—å—Ç—Ä–æ–≤–∞–Ω–æ={filtered_count}, "
        f"—É–∂–µ –æ—Ç–ø—Ä–∞–≤–ª–µ–Ω–æ={already_sent_count}, "
        f"–¥—É–±–ª–∏–∫–∞—Ç—ã={duplicate_count}, "
        f"–æ—à–∏–±–∫–∏ –æ—Ç–ø—Ä–∞–≤–∫–∏={failed_send_count}, "
        f"–æ—Ç–ø—Ä–∞–≤–ª–µ–Ω–æ={user_new_count}",
    )

    if user_new_count > 0:
        log_info(
            "search",
            f"–ü–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—é {user_id} –æ—Ç–ø—Ä–∞–≤–ª–µ–Ω–æ: {user_new_count} –æ–±—ä—è–≤–ª–µ–Ω–∏–π",
        )
    elif len(all_listings) > 0:
        log_warning(
            "search",
            f"[user_{user_id}] ‚ö†Ô∏è –í—Å–µ {len(all_listings)} –æ–±—ä—è–≤–ª–µ–Ω–∏–π –±—ã–ª–∏ –æ—Ç—Ñ–∏–ª—å—Ç—Ä–æ–≤–∞–Ω—ã –∏–ª–∏ —É–∂–µ –æ—Ç–ø—Ä–∞–≤–ª–µ–Ω—ã!",
        )

    return user_new_count


async def check_new_listings(
    bot: Any,
    force_send: bool = False,
    ignore_sent_ads: bool = False,
    bypass_summary: bool = False
) -> None:
    """
    –ü—Ä–æ–≤–µ—Ä—è–µ—Ç –Ω–æ–≤—ã–µ –æ–±—ä—è–≤–ª–µ–Ω–∏—è –∏ –æ—Ç–ø—Ä–∞–≤–ª—è–µ—Ç –∏—Ö –∞–∫—Ç–∏–≤–Ω—ã–º –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è–º.
    
    Args:
        bot: –≠–∫–∑–µ–º–ø–ª—è—Ä –±–æ—Ç–∞
        force_send: –ü—Ä–∏–Ω—É–¥–∏—Ç–µ–ª—å–Ω–∞—è –æ—Ç–ø—Ä–∞–≤–∫–∞ (–∏–≥–Ω–æ—Ä–∏—Ä—É–µ—Ç –Ω–µ–∫–æ—Ç–æ—Ä—ã–µ –ø—Ä–æ–≤–µ—Ä–∫–∏)
        ignore_sent_ads: –ò–≥–Ω–æ—Ä–∏—Ä–æ–≤–∞—Ç—å –ø—Ä–æ–≤–µ—Ä–∫—É sent_ads
        bypass_summary: –û–±–æ–π—Ç–∏ summary –∏ –æ—Ç–ø—Ä–∞–≤–ª—è—Ç—å –ø–æ–ª–Ω—ã–µ —É–≤–µ–¥–æ–º–ª–µ–Ω–∏—è
    """
    from bot.services.ai_service import check_new_listings_ai_mode
    from bot.handlers.debug import get_debug_ignore_sent_ads
    
    # –õ–æ–≥–∏—Ä–æ–≤–∞–Ω–∏–µ debug run –ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤
    debug_ignore_sent_ads = get_debug_ignore_sent_ads()
    logger.info(f"[debug_run] force_send={force_send} ignore_sent_ads={ignore_sent_ads} bypass_summary={bypass_summary} debug_ignore_sent_ads={debug_ignore_sent_ads}")

    reset_filter_counters()

    log_info("search", "=" * 50)
    log_info("search", "–ü—Ä–æ–≤–µ—Ä–∫–∞ –Ω–æ–≤—ã—Ö –æ–±—ä—è–≤–ª–µ–Ω–∏–π —Å–æ –≤—Å–µ—Ö –∏—Å—Ç–æ—á–Ω–∏–∫–æ–≤...")

    # –ü–æ–ª—É—á–∞–µ–º —Å–ø–∏—Å–æ–∫ –∞–∫—Ç–∏–≤–Ω—ã—Ö –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª–µ–π
    # #region agent log
    import json
    import time
    try:
        with open('/Users/vmakhakei/TG BOT/.cursor/debug.log', 'a') as f:
            f.write(json.dumps({"sessionId":"debug-session","runId":"run1","hypothesisId":"A","location":"search_service.py:513","message":"check_new_listings: calling get_active_users","data":{},"timestamp":int(time.time()*1000)})+'\n')
    except: pass
    # #endregion
    active_users = await get_active_users()
    
    # –î–∏–∞–≥–Ω–æ—Å—Ç–∏—á–µ—Å–∫–∏–π –ª–æ–≥: 100% –ø–æ–Ω–∏–º–∞–Ω–∏–µ, –ø–æ—á–µ–º—É —É–≤–µ–¥–æ–º–ª–µ–Ω–∏—è –Ω–µ –∏–¥—É—Ç
    logger.info(
        "[search][diag] active_users=%s ids=%s",
        len(active_users),
        active_users
    )
    
    # #region agent log
    try:
        with open('/Users/vmakhakei/TG BOT/.cursor/debug.log', 'a') as f:
            f.write(json.dumps({"sessionId":"debug-session","runId":"run1","hypothesisId":"A","location":"search_service.py:516","message":"check_new_listings: get_active_users result","data":{"count":len(active_users),"user_ids":active_users},"timestamp":int(time.time()*1000)})+'\n')
    except: pass
    # #endregion

    # –õ–æ–≥-–≤–∞–ª–∏–¥–∞—Ü–∏—è: –æ–±—è–∑–∞—Ç–µ–ª—å–Ω–æ –ª–æ–≥–∏—Ä—É–µ–º –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –Ω–∞–π–¥–µ–Ω–Ω—ã—Ö –∞–∫—Ç–∏–≤–Ω—ã—Ö –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª–µ–π
    logger.info(
        "[search] found %d active users",
        len(active_users)
    )
    log_info("search", f"–ù–∞–π–¥–µ–Ω–æ –∞–∫—Ç–∏–≤–Ω—ã—Ö –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª–µ–π: {len(active_users)}")
    
    if not active_users:
        log_info("search", "–ù–µ—Ç –∞–∫—Ç–∏–≤–Ω—ã—Ö –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª–µ–π - –ø—Ä–æ–≤–µ—Ä—å—Ç–µ, —á—Ç–æ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª–∏ –∑–∞–ø—É—Å–∫–∞–ª–∏ /start")
        return

    total_sent = 0

    # –î–ª—è –∫–∞–∂–¥–æ–≥–æ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è –ø—Ä–æ–≤–µ—Ä—è–µ–º –æ–±—ä—è–≤–ª–µ–Ω–∏—è –ø–æ –µ–≥–æ —Ñ–∏–ª—å—Ç—Ä–∞–º
    for user_id in active_users:
        # #region agent log
        try:
            with open('/Users/vmakhakei/TG BOT/.cursor/debug.log', 'a') as f:
                f.write(json.dumps({"sessionId":"debug-session","runId":"run1","hypothesisId":"A","location":"search_service.py:524","message":"Processing user","data":{"user_id":user_id},"timestamp":int(time.time()*1000)})+'\n')
        except: pass
        # #endregion
        # –û–î–ò–ù –ò–°–¢–û–ß–ù–ò–ö –§–ò–õ–¨–¢–†–û–í: —Ç–æ–ª—å–∫–æ Turso, –±–µ–∑ fallback –Ω–∞ SQLite
        user_filters = await get_user_filters_turso(user_id)
        
        # –ß–ê–°–¢–¨ D ‚Äî –ë–õ–û–ö–ò–†–û–í–ö–ê –ü–û–ò–°–ö–ê –ë–ï–ó –§–ò–õ–¨–¢–†–û–í (–§–ò–ù–ê–õ–¨–ù–û)
        if not user_filters or not user_filters.get("city"):
            await bot.send_message(
                user_id,
                "‚ö†Ô∏è –°–Ω–∞—á–∞–ª–∞ –Ω–∞—Å—Ç—Ä–æ–π—Ç–µ —Ñ–∏–ª—å—Ç—Ä—ã"
            )
            logger.warning(f"[SEARCH_BLOCKED] user={user_id} filters missing or city not set")
            continue
        
        # –ñ–Å–°–¢–ö–ê–Ø –î–ò–ê–ì–ù–û–°–¢–ò–ö–ê: –ª–æ–≥–∏—Ä—É–µ–º –∏—Å—Ç–æ—á–Ω–∏–∫ —Ñ–∏–ª—å—Ç—Ä–æ–≤
        logger.critical(
            f"[FILTER_DUMP] user={user_id} filters={user_filters} source=TURSO"
        )
        
        # –§–ò–ù–ê–õ–¨–ù–´–ô –õ–û–ì: –æ–¥–Ω–æ–∑–Ω–∞—á–Ω–æ –ø–æ–∫–∞–∑—ã–≤–∞–µ—Ç –≤–∞–ª–∏–¥–Ω–æ—Å—Ç—å —Ñ–∏–ª—å—Ç—Ä–æ–≤
        filters_valid = has_valid_user_filters(user_filters)
        logger.critical(
            f"[SEARCH_ENTRY] user={user_id} filters_valid={filters_valid}"
        )
        
        # #region agent log
        try:
            with open('/Users/vmakhakei/TG BOT/.cursor/debug.log', 'a') as f:
                f.write(json.dumps({"sessionId":"debug-session","runId":"run1","hypothesisId":"A","location":"search_service.py:526","message":"User filters retrieved","data":{"user_id":user_id,"has_filters":user_filters is not None,"is_active":user_filters.get("is_active") if user_filters else None},"timestamp":int(time.time()*1000)})+'\n')
        except: pass
        # #endregion
        
        # –ï–î–ò–ù–ê–Ø –ü–†–û–í–ï–†–ö–ê –§–ò–õ–¨–¢–†–û–í: –∏—Å–ø–æ–ª—å–∑—É–µ–º has_valid_user_filters
        # DEBUG RUN –¥–æ–ª–∂–µ–Ω –∏–≥–Ω–æ—Ä–∏—Ä–æ–≤–∞—Ç—å –ø—Ä–æ–≤–µ—Ä–∫—É —Ñ–∏–ª—å—Ç—Ä–æ–≤
        from bot.handlers.debug import get_debug_force_run, get_debug_skip_filter_validation
        debug_force_run = get_debug_force_run()
        skip_filter_validation = get_debug_skip_filter_validation()
        
        if skip_filter_validation:
            logger.warning("[DEBUG] Skipping filter validation")
        elif not has_valid_user_filters(user_filters):
            if not force_send and not debug_force_run:
                logger.critical(
                    f"[FILTER_STATE] user={user_id} filters invalid ‚Üí redirect to setup"
                )
                # –ë–õ–û–ö–ò–†–û–í–ö–ê –ü–û–ò–°–ö–ê: –µ—Å–ª–∏ —Ñ–∏–ª—å—Ç—Ä—ã –Ω–µ —Å–æ—Ö—Ä–∞–Ω–∏–ª–∏—Å—å
                await bot.send_message(
                    user_id,
                    "‚ö†Ô∏è –§–∏–ª—å—Ç—Ä—ã –Ω–µ —Å–æ—Ö—Ä–∞–Ω–µ–Ω—ã. –ü–æ–∂–∞–ª—É–π—Å—Ç–∞, –Ω–∞—Å—Ç—Ä–æ–π—Ç–µ —Ñ–∏–ª—å—Ç—Ä—ã –∑–∞–Ω–æ–≤–æ."
                )
                await _send_setup_filters_message(bot, user_id)
                continue
            
            # –í–†–ï–ú–ï–ù–ù–´–ô FAIL-SAFE: –¥–ª—è DEBUG —Ä–µ–∂–∏–º–∞ –∏—Å–ø–æ–ª—å–∑—É–µ–º –¥–µ—Ñ–æ–ª—Ç–Ω—ã–µ —Ñ–∏–ª—å—Ç—Ä—ã
            if force_send or debug_force_run:
                logger.critical("[FILTER_FAILSAFE] forcing default filters for DEBUG run")
                user_filters = {
                    "city": "–±–∞—Ä–∞–Ω–æ–≤–∏—á–∏",
                    "min_rooms": 1,
                    "max_rooms": 4,
                    "min_price": 0,
                    "max_price": 100000,
                    "is_active": True,
                    "ai_mode": False,
                    "seller_type": None
                }
            else:
                continue

        # –ü—Ä–æ–≤–µ—Ä—è–µ–º –≤–∞–ª–∏–¥–Ω–æ—Å—Ç—å —Ñ–∏–ª—å—Ç—Ä–æ–≤ (–∏—Å–ø–æ–ª—å–∑—É–µ–º –µ–¥–∏–Ω—É—é —Ñ—É–Ω–∫—Ü–∏—é)
        if not skip_filter_validation and not has_valid_user_filters(user_filters):
            log_warning("bot", f"–ü—Ä–æ–ø—É—Å–∫–∞—é –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è {user_id}: —Ñ–∏–ª—å—Ç—Ä—ã –Ω–µ–≤–∞–ª–∏–¥–Ω—ã")
            continue

        # –ü–æ–ª—É—á–∞–µ–º –æ–±—ä—è–≤–ª–µ–Ω–∏—è –¥–ª—è –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è
        all_listings = await fetch_listings_for_user(user_id, user_filters)

        # –î–ò–ê–ì–ù–û–°–¢–ò–ö–ê: –ø—Ä–æ–≤–µ—Ä—è–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç –ø–æ–ª—É—á–µ–Ω–∏—è –æ–±—ä—è–≤–ª–µ–Ω–∏–π
        if all_listings is None:
            log_error("search", f"[user_{user_id}] ‚ùå fetch_listings_for_user –≤–µ—Ä–Ω—É–ª None!")
            continue

        if not isinstance(all_listings, list):
            log_error("search", f"[user_{user_id}] ‚ùå fetch_listings_for_user –≤–µ—Ä–Ω—É–ª –Ω–µ —Å–ø–∏—Å–æ–∫: {type(all_listings)}")
            continue

        log_info("search", f"[user_{user_id}] üì• –ü–æ–ª—É—á–µ–Ω–æ –æ–±—ä—è–≤–ª–µ–Ω–∏–π: {len(all_listings)}")

        # –ü—Ä–æ–≤–µ—Ä—è–µ–º —Ä–µ–∂–∏–º —Ä–∞–±–æ—Ç—ã –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è
        if user_filters.get("ai_mode"):
            # –ò–ò-—Ä–µ–∂–∏–º: –ø–µ—Ä–µ–¥–∞–µ–º –≤—Å–µ –æ–±—ä—è–≤–ª–µ–Ω–∏—è –≤ —Ñ—É–Ω–∫—Ü–∏—é –ò–ò-—Ä–µ–∂–∏–º–∞
            await check_new_listings_ai_mode(bot, user_id, user_filters, all_listings)
        else:
            # –û–±—ã—á–Ω—ã–π —Ä–µ–∂–∏–º: –æ—Ç–ø—Ä–∞–≤–ª—è–µ–º –≤—Å–µ –ø–æ–¥—Ö–æ–¥—è—â–∏–µ –æ–±—ä—è–≤–ª–µ–Ω–∏—è
            user_new_count = await _process_user_listings_normal_mode(
                bot, user_id, all_listings, user_filters, ignore_sent_ads=ignore_sent_ads
            )
            total_sent += user_new_count

    # –î–ò–ê–ì–ù–û–°–¢–ò–ö–ê: —Ñ–∏–Ω–∞–ª—å–Ω–∞—è —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞
    if total_sent > 0:
        log_info("search", f"‚úÖ –í—Å–µ–≥–æ –æ—Ç–ø—Ä–∞–≤–ª–µ–Ω–æ –Ω–æ–≤—ã—Ö –æ–±—ä—è–≤–ª–µ–Ω–∏–π: {total_sent}")
    else:
        log_warning("search", "‚ö†Ô∏è –ù–æ–≤—ã—Ö –æ–±—ä—è–≤–ª–µ–Ω–∏–π –Ω–µ—Ç - –ø—Ä–æ–≤–µ—Ä—å—Ç–µ —Ñ–∏–ª—å—Ç—Ä—ã –∏ –ª–æ–≥–∏ –≤—ã—à–µ")

    log_info("search", "=" * 50)


async def _send_setup_filters_message(bot: Any, telegram_id: int) -> None:
    """
    –û—Ç–ø—Ä–∞–≤–ª—è–µ—Ç –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—é —Å–æ–æ–±—â–µ–Ω–∏–µ —Å –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏–µ–º –Ω–∞—Å—Ç—Ä–æ–∏—Ç—å —Ñ–∏–ª—å—Ç—Ä—ã
    
    Args:
        bot: –≠–∫–∑–µ–º–ø–ª—è—Ä –±–æ—Ç–∞
        telegram_id: ID –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è –≤ Telegram
    """
    try:
        from aiogram.types import InlineKeyboardMarkup, InlineKeyboardButton
        
        keyboard = InlineKeyboardMarkup(inline_keyboard=[[
            InlineKeyboardButton(
                text="‚öôÔ∏è –ù–∞—Å—Ç—Ä–æ–∏—Ç—å —Ñ–∏–ª—å—Ç—Ä—ã",
                callback_data="setup_filters"
            )
        ]])
        
        await bot.send_message(
            telegram_id,
            "‚ö†Ô∏è –£ –≤–∞—Å –Ω–µ –Ω–∞—Å—Ç—Ä–æ–µ–Ω—ã —Ñ–∏–ª—å—Ç—Ä—ã.\n\n–î–∞–≤–∞–π—Ç–µ –Ω–∞—Å—Ç—Ä–æ–∏–º –∏—Ö –∑–∞–Ω–æ–≤–æ üëá",
            reply_markup=keyboard
        )
        
        logger.info(f"[filters] Redirected user {telegram_id} to filter setup wizard")
    except Exception as e:
        logger.error(f"[filters] Failed to send message to user {telegram_id}: {e}")
